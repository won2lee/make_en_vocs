{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "subtle-round",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step_1 XX : 10002\n",
      "True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e27e7e416899499c8648138e35d0d458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "|          | 0/0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated items : 0,  added items : 0\n",
      "step_2 XX : 10002\n",
      "True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0d7d956f2541da81e4d21b0795da39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/34 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated items : 33,  added items : 1\n",
      "step_3 XX : 9970\n",
      "True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee91ac2f367848ebb68dccddaf55d3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated items : 4,  added items : 0\n",
      "step_4 XX : 9967\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4c3fc39bc94a5fb456a5b0b329ddc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated items : 22,  added items : 0\n",
      "step_5 XX : 9946\n",
      "True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6d0264e0094b35ae389526846589fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated items : 252,  added items : 35\n",
      "step_6 XX : 9696\n",
      "True\n",
      "step_7 XX : 9442\n",
      "step_1 XX : 699367\n",
      "True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c053c51bcad740b698d23082bbeac048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84132 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated items : 83745,  added items : 387\n",
      "step_2 XX : 615623\n",
      "True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7d0da83caf468da93cc1c04f9e2984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18946 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated items : 18946,  added items : 0\n",
      "step_3 XX : 596678\n",
      "True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91bd3d4998724261be4cabf5e29651d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2985 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated items : 2985,  added items : 0\n",
      "step_4 XX : 593694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a70c8feb8cc4f199a7dcfa84cfbe02e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated items : 1725,  added items : 0\n",
      "step_5 XX : 591958\n",
      "True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf05a0fc9da46eba5ef10e095e7b5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated items : 22398,  added items : 2778\n",
      "step_6 XX : 556391\n",
      "True\n",
      "step_7 XX : 519003\n"
     ]
    }
   ],
   "source": [
    "#####################################\n",
    "\n",
    "#   6.15 version\n",
    "\n",
    "#####################################\n",
    "\n",
    "import re\n",
    "import copy\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from util_func import json_read, json_save, dict_merge, voc_combined, add_item, modi_dict\n",
    "#from utils import json_save, json_read, voc_combined, special_to_normal\n",
    "#from counter_vocab_tuning import dict_merge\n",
    "\n",
    "\"\"\"\n",
    "def json_save(data, f_name):\n",
    "    import json\n",
    "    json = json.dumps(data)\n",
    "    with open(f_name +\".json\",\"w\") as f:\n",
    "        f.write(json) \n",
    "\n",
    "def json_read(f_name):\n",
    "    import json\n",
    "    with open(f_name) as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def dict_merge(src_dict, tgt_dict):\n",
    "    \n",
    "    updated_items = 0\n",
    "    added_items = 0\n",
    "    \n",
    "    for k,v in tqdm(src_dict.items()):\n",
    "        if k in tgt_dict.keys():\n",
    "            tgt_dict[k] =  tgt_dict[k] + v \n",
    "            updated_items += 1\n",
    "        else:\n",
    "            tgt_dict[k] = v\n",
    "            added_items += 1\n",
    "    \n",
    "    print(\"updated items : {},  added items : {}\".format(updated_items, added_items)) \n",
    "    \n",
    "    return updated_items, added_items\n",
    "\n",
    "def voc_combined(vocab):\n",
    "    vocab_sub = {}\n",
    "    #for k, v in vocab:\n",
    "    for k, v in vocab.items():\n",
    "        for s in k.split(' '): \n",
    "            if s in vocab_sub.keys():\n",
    "                vocab_sub[s] += v\n",
    "            else:\n",
    "                vocab_sub[s] = v\n",
    "    return vocab_sub, len(vocab_sub)\n",
    "    \n",
    "def add_item(k,v,dct):\n",
    "    if k in dct.keys():\n",
    "        dct[k] += v\n",
    "    else:\n",
    "        dct[k] = v\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def bpe_voc_in_normal(bpe_vocabs):\n",
    "    voc_ex, _ = voc_combined(bpe_vocabs)\n",
    "    sorted_voc_ex = sorted(voc_ex.items(), key=lambda x:x[1], reverse=True)\n",
    "    #readable = [(special_to_normal(k,key_vars),v) for k, v in sorted_voc_ex]\n",
    "    return sorted_voc_ex\n",
    "    #return readable, sorted_voc_ex\n",
    "\n",
    "\n",
    "        \n",
    "path = \"data/\"\n",
    "\n",
    "new_bpe_vocabs = json_read(path+'bpe_iter/vocabs10000.json')\n",
    "after_bpe = bpe_voc_in_normal(new_bpe_vocabs)\n",
    "Xstart = dict(after_bpe)\n",
    "#XX = copy.deepcopy(Xstart)\n",
    "\n",
    "vocabs = json_read(path+'counted_vocs.json')\n",
    "Xvocs = {}\n",
    "for w,v in vocabs.items():\n",
    "    add_item(w.lower(),v,Xvocs)\n",
    "vocabs = copy.deepcopy(Xvocs) \n",
    "to_save = ['bpe30', 'count30']\n",
    "\n",
    "for ik,vcs_set in enumerate([Xstart, vocabs]):\n",
    "    XX = copy.deepcopy(vcs_set)\n",
    "    XXX = copy.deepcopy(XX)\n",
    "    print(\"step_1 XX : {}\".format(len(XX)))\n",
    "    print('success' in XX.keys())\n",
    "\n",
    "    Xa = {}\n",
    "    for k,v in XX.items():\n",
    "        if (len(k) >3 and k[-1] =='.' and (k[:-1] in vocabs.keys())):\n",
    "            modi_dict(k,1,v,Xa,XXX)\n",
    "            \"\"\"\n",
    "            add_item(k[:-1], v, Xa)\n",
    "            add_item(k[-1:], v, Xa)\n",
    "            XXX.pop(k,1)\n",
    "            \"\"\"\n",
    "    _,_ = dict_merge(Xa,XXX)\n",
    "    XX = copy.deepcopy(XXX)\n",
    "    print(\"step_2 XX : {}\".format(len(XX)))\n",
    "    print('success' in XX.keys())\n",
    "\n",
    "    Xa = {}\n",
    "    for k,v in XX.items():\n",
    "        if (len(k) > 6 and k[-1] ==\"s\" and k[-2:] not in [\"es\",\"ss\"] and \n",
    "            k in vocabs.keys() and k[:-1] in vocabs.keys()) and vocabs[k[:-1]] > 0.2 * vocabs[k]:\n",
    "            modi_dict(k,1,v,Xa,XXX)\n",
    "            \"\"\"\n",
    "            add_item(k[:-1], v, Xa)\n",
    "            add_item(k[-1:], v, Xa)\n",
    "            XXX.pop(k,1)\n",
    "            \"\"\"\n",
    "\n",
    "    _,_ = dict_merge(Xa,XXX)\n",
    "    XX = copy.deepcopy(XXX)\n",
    "    print(\"step_3 XX : {}\".format(len(XX)))\n",
    "    print('success' in XX.keys())\n",
    "    \n",
    "    Xa = {}\n",
    "    for k,v in XX.items():\n",
    "        if (len(k) > 6 and k[-2:] =='ly' and \n",
    "            k in vocabs.keys() and k[:-2] in vocabs.keys() and vocabs[k[:-2]] > 0.2 * vocabs[k]):\n",
    "            modi_dict(k,2,v,Xa,XXX)\n",
    "            \"\"\"\n",
    "            add_item(k[:-2], v, Xa)\n",
    "            add_item(k[-2:], v, Xa)\n",
    "            XXX.pop(k,1)\n",
    "\n",
    "            \"\"\"\n",
    "\n",
    "    _,_ = dict_merge(Xa,XXX)\n",
    "    XX = copy.deepcopy(XXX)\n",
    "    print(\"step_4 XX : {}\".format(len(XX)))\n",
    "\n",
    "    Xa = {}\n",
    "    for k,v in XX.items():\n",
    "        if (len(k) >7 and k[-4:] in ['ness','ment'] and \n",
    "            k in vocabs.keys() and k[:-4] in vocabs.keys() and vocabs[k[:-4]] > 0.2 * vocabs[k]):\n",
    "            modi_dict(k,4,v,Xa,XXX)\n",
    "            \"\"\"\n",
    "            add_item(k[:-4], v, Xa)\n",
    "            add_item(k[-4:], v, Xa)\n",
    "            XXX.pop(k,1)\n",
    "            \"\"\"\n",
    "\n",
    "    _,_ = dict_merge(Xa,XXX)\n",
    "    XX = copy.deepcopy(XXX)\n",
    "    print(\"step_5 XX : {}\".format(len(XX))) \n",
    "    print('success' in XX.keys())\n",
    "\n",
    "    for k,v in XX.items():\n",
    "\n",
    "        if (len(k) > 8 and k[-5:] =='ation' and k in vocabs.keys() and k[:-5]+'ed' in vocabs.keys() and \n",
    "            ((k[:-5] in vocabs.keys() and vocabs[k[:-5]] > 0.2 * vocabs[k]) or \n",
    "             (k[:-5]+'e' in vocabs.keys() and vocabs[k[:-5]+'e'] > 0.2 * vocabs[k]))):\n",
    "            modi_dict(k,5,v,Xa,XXX)\n",
    "            \"\"\"\n",
    "            add_item(k[:-5], v, Xa)\n",
    "            add_item(k[-5:], v, Xa)\n",
    "            XXX.pop(k,1)\n",
    "            \"\"\"\n",
    "\n",
    "        elif (len(k) > 6 and k[-3:] in ['ion', 'ing'] and k in vocabs.keys() and k[:-3]+'ed' in vocabs.keys() and\n",
    "              ((k[-5] == k[-4] and k[:-3] in vocabs.keys() and k[:-4] not in vocabs.keys()) or \n",
    "               (k[-5] != k[-4] and ((k[:-3] in vocabs.keys() and vocabs[k[:-3]] > 0.2 * vocabs[k]) \n",
    "                    or (k[:-3]+'e' in vocabs.keys() and vocabs[k[:-3]+'e'] > 0.2 * vocabs[k]))))): # discuss 와 같은 경우 \n",
    "            modi_dict(k,3,v,Xa,XXX)\n",
    "            \"\"\"\n",
    "            dd_item(k[:-3], v, Xa)\n",
    "            add_item(k[-3:], v, Xa)  \n",
    "            XXX.pop(k,1) \n",
    "            \"\"\"\n",
    "\n",
    "        elif (len(k) > 5 and k[-2:] in ['ed','es','er'] and \n",
    "              ((k[-3] == k[-4] and k[:-2] in vocabs.keys() and k[:-3] not in vocabs.keys()) or \n",
    "               (k[-3] != k[-4] and (k[:-2] in vocabs.keys() or k[:-2]+'e' in vocabs.keys()))) and \n",
    "              k in vocabs.keys() and k[:-2]+'ing' in vocabs.keys()):\n",
    "            modi_dict(k,2,v,Xa,XXX)\n",
    "            \"\"\"\n",
    "            add_item(k[:-2], v, Xa)\n",
    "            add_item(k[-2:], v, Xa)\n",
    "            XXX.pop(k,1)\n",
    "\n",
    "            \"\"\"         \n",
    "\n",
    "        elif (len(k) > 4 and k[-2:] == \"'s\" and k[:-2] in vocabs.keys()):\n",
    "            modi_dict(k,2,v,Xa,XXX)\n",
    "            \"\"\"\n",
    "            add_item(k[:-2], v, Xa)\n",
    "            add_item(k[-2:], v, Xa)\n",
    "            XXX.pop(k,1)\n",
    "            \"\"\"\n",
    " \n",
    "        elif (len(k) > 4 and k[-1:] in [\"s\"] and k[-2:] not in [\"es\",\"ss\"] and k in vocabs.keys() and \n",
    "              k[:-1] in vocabs.keys() and vocabs[k[:-1]] > 0.3*vocabs[k]):\n",
    "            modi_dict(k,1,v,Xa,XXX)\n",
    "            \"\"\"\n",
    "            add_item(k[:-1], v, Xa)\n",
    "            add_item(k[-1:], v, Xa)\n",
    "            XXX.pop(k,1)\n",
    "            \"\"\" \n",
    "\n",
    "        elif (len(k) > 4 and k[-1:] in [\"e\"] and k in vocabs.keys() and \n",
    "              k[:-1]+'ing' in vocabs.keys() and k[:-1]+'ed' in vocabs.keys() and \n",
    "              vocabs[k] < vocabs[k[:-1]+'ing'] + vocabs[k[:-1]+'ed']):\n",
    "            modi_dict(k,1,v,Xa,XXX)\n",
    "            \"\"\"\n",
    "            add_item(k[:-1], v, Xa)\n",
    "            add_item(k[-1:], v, Xa)\n",
    "            XXX.pop(k,1)\n",
    "            \"\"\"\n",
    "\n",
    "    _,_ = dict_merge(Xa,XXX)        \n",
    "    XX = copy.deepcopy(XXX) \n",
    "    print(\"step_6 XX : {}\".format(len(XX)))\n",
    "    print('success' in XX.keys())\n",
    "\n",
    "    p = re.compile('.*[0-9]+.*')\n",
    "    for k,v in XX.items():\n",
    "        if p.sub('',k) =='':\n",
    "            XXX.pop(k,1) \n",
    "    XX = copy.deepcopy(XXX) \n",
    "    print(\"step_7 XX : {}\".format(len(XX)))\n",
    "        \n",
    "        \n",
    "    if ik == 1:\n",
    "        XX = dict(sorted(XX.items(), key=lambda x:x[1],reverse=True)[:30000])\n",
    "    json_save(XX,path+'en_vocabs/'+to_save[ik]+'_0615_check')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "personal-deviation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 9442\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0563a235602f453e89cd660085225bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9442 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated items : 6873,  added items : 2569\n",
      "32569 1408\n",
      "33391 1408\n"
     ]
    }
   ],
   "source": [
    "vocsX = json_read(path+'en_vocabs/count30_0615.json')\n",
    "X30000 = json_read(path+'en_vocabs/bpe30_0615.json')\n",
    "print(len(vocsX), len(X30000))\n",
    "_,_ = dict_merge(X30000,vocsX)\n",
    "Xffix = json_read(path+'en_vocabs/pre_suf_fix.json')\n",
    "print(len(vocsX), len(Xffix['prefix']))\n",
    "vocsX.update(Xffix['prefix'])\n",
    "vocsX.update(Xffix['suffix'])\n",
    "print(len(vocsX), len(Xffix['prefix']))\n",
    "json_save(vocsX,path+'en_vocabs/en_vocabs_to_apply.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceramic-israel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "nasty-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa = sorted(Xstart.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "productive-medicaid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('signific', 5),\n",
       " ('ijing', 5),\n",
       " ('tware', 5),\n",
       " ('wegian', 4),\n",
       " ('frontr', 4),\n",
       " ('eroon', 4),\n",
       " ('busin', 4),\n",
       " ('cese', 4),\n",
       " ('bassy', 4),\n",
       " ('thous', 4),\n",
       " ('ontar', 4),\n",
       " ('perior', 4),\n",
       " ('caust', 3),\n",
       " ('acare', 3),\n",
       " ('indigen', 3),\n",
       " ('efire', 3),\n",
       " ('devel', 3),\n",
       " ('glig', 3),\n",
       " ('roose', 3),\n",
       " ('caine', 3)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adjusted-peace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10002"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-hampshire",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
